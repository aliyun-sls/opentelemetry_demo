# 默认为 arms-dev 账号
server.port=9190
service.name=${SERVICE_NAME}
spring.application.name=${SERVICE_NAME}
#service.names=insights-server-0,insights-server-1,insights-server-2,insights-server-3,external-http-server-0,external-http-server-1,\
#  insights-redis-server,insights-mysql-server,insights-mysql-connection,mall-product-server,mall-user-server,mall-cart-server,mall-gateway,\
#  insights-kafka-producer
service.names=${MOCK_SERVICE_NAMES}
service.serverUrls=${MOCK_SERVICE_SERVER_URLS}

#service.serverUrls=http://insights-service-0:9190/,http://insights-service-1:9190/,http://insights-service-2:9190/,http://insights-service-3:9190/,\
#  http://external-http-service-0:9190/,http://external-http-service-1:9190/,\
#  http://insights-redis-service:9190/,http://insights-mysql-service:9190/,http://insights-mysql-connection-service:9190/,\
#  http://mall-product-service:9190/,http://mall-user-service:9190/,http://mall-cart-service:9190/,http://mall-gateway-service:9190/,\
#  http://insights-kafka-producer-service:9190
swagger.enabled=false

#外部服务地址
external.service.addr=http://external-http-service-0:9190/
external.service.connection.addr=http://external-http-service-1:9190/
# dubbo配置
dubbo.scan.base-packages=com.alibaba.arms.mock.server.service
# Dubbo Protocol
dubbo.protocol.name=dubbo
## Random port
dubbo.protocol.port=-1
## Dubbo Registry
#dubbo.registry.address=zookeeper://10.0.129.108:2181
dubbo.registry.address=multicast://224.5.6.7:1234
mybatis.mapper-locations=classpath:com/alibaba/arms/mock/dao/xml/*.xml
mybatis.type-aliases-package=com.alibaba.arms.mock.dao.entity
mybatis.configuration.map-underscore-to-camel-case=true
mybatis.configuration.default-fetch-size=100
mybatis.configuration.default-statement-timeout=30
# MySQL
spring.datasource.url=jdbc:mysql://${MYSQL_ENDPOINT}:3306/${MYSQL_DATABASE}
spring.datasource.username=${MYSQL_USER}
spring.datasource.password=${MYSQL_PASSWORD}
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
# 初始化时建立物理连接的个数
spring.datasource.druid.initial-size=5
# 最大连接池数量
spring.datasource.druid.max-active=5
# 最小连接池数量
spring.datasource.druid.min-idle=5
# 获取连接时最大等待时间，单位毫秒
spring.datasource.druid.max-wait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.druid.time-between-eviction-runs-millis=60000
# 连接保持空闲而不被驱逐的最小时间
spring.datasource.druid.min-evictable-idle-time-millis=300000
# 用来检测连接是否有效的sql，要求是一个查询语句
spring.datasource.druid.validation-query=SELECT 1 FROM DUAL
# 建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。
spring.datasource.druid.test-while-idle=true
# 申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。
spring.datasource.druid.test-on-borrow=false
# 归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。
spring.datasource.druid.test-on-return=false
# 是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。
spring.datasource.druid.pool-prepared-statements=true
# 要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。
spring.datasource.druid.max-pool-prepared-statement-per-connection-size=50
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计
spring.datasource.druid.filters=stat,wall
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.druid.connection-properties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500
# 合并多个DruidDataSource的监控数据
spring.datasource.druid.use-global-data-source-stat=true
# Redis
################ Redis 基础配置 ##############
# Redis数据库索引（默认为0）
spring.redis.database=0
# Redis服务器地址
spring.redis.host=${REDIS_HOST}
# Redis服务器连接端口
spring.redis.port=6379

# 链接超时时间 单位 ms（毫秒）
spring.redis.timeout=3000
################ Redis 线程池设置 ##############
# 连接池最大连接数（使用负值表示没有限制） 默认 8
spring.redis.jedis.pool.max-active=8
# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1
spring.redis.jedis.pool.max-wait=-1
# 连接池中的最大空闲连接 默认 8
spring.redis.jedis.pool.max-idle=8
# 连接池中的最小空闲连接 默认 0
spring.redis.jedis.pool.min-idle=0

# Kafka
################ Kafka 基础配置 ##############
# Kafka Server endpoint
spring.kafka.bootstrap-servers=${KAFKA_SERVICE_ADDR}
# Kafka consume config
spring.kafka.consumer.group-id=arms-demo-consumer-group-1
spring.kafka.consumer.max-poll-records=30
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# Kafka topics
kafka.topics=arms-apm-demo-topic

##
rocketmq.producer.enable=false
rocketmq.consumer.enable=false
